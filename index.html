<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Addressing the ID-Matching Challenge in Long Video Captioning</title>
  <link rel="icon" type="image/x-icon" href="static/images/head.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Addressing the ID-Matching Challenge in Long Video Captioning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Zhantao Yang</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Huangji Wang</a><sup>*</sup>,</span>
                  <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Ruili Feng</a></sup>,</span>
                  <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Han Zhang</a></sup>,</span>
                  <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Yuting Hu</a></sup>,</span>
                  <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Shangwen Zhu</a></sup>,</span>
                  <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Junyan Li</a></sup>,</span>
                  <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Yu Liu</a></sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Fan Cheng</a>
                  </span>
                  
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Shanghai Jiao Tong University<br> Alibaba group</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          This paper addresses the ID-Matching challenge in long video captioning, which is crucial for generating accurate captions in text-to-video tasks. Previous methods have been limited in generalization and relied on point-wise matching. This paper introduces a new benchmark for evaluating ID-Matching performance in captions and proposes a novel method, Recognizing Identities for Captioning Effectively (RICE), built on LVLMs (Large Vision-Language Models) like GPT-4o. The approach enhances ID-Matching performance by improving the usage of image information and increasing the quantity of individual descriptions. Experimental results show that RICE significantly boosts ID-Matching precision (from 50% to 90%) and recall (from 15% to 80%).


          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-full">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            There is an example of video captions for a video lasting around 480 seconds (around 200 key
 frames) obtained by: GPT-4o, ShareGPT4Video, and RICE. For simplicity, we have left out some
 intermediate key frames and their captions. The results show that RICE generates more detailed
 and accurate captions while keeping tracking the main individuals throughout the long video
 (The repeatedly appearing individuals are highlighted in different colors.) In contrast, GPT-4o and
 ShareGPT4Video lose track of key individuals over time, misinterpreting content about one person as
 involving multiple people.


          </p>

          <img src="static\images\pic1.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">

          <p><br><br>
            The method for automatically extracting the predicted \task sequence from the caption involves two steps: 1) Given the video frames and the caption, extract the IDs and their corresponding descriptions for each frame; 2) Extract the \task sequence by sequentially comparing the descriptions of the IDs in the current frame with those in the previous frame to determine whether they are the same ID. 
          </p>
          <img src="static\images\pic2.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">

        </div>
      </div>
    </div>
  </div>
</section>





<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-full">
        <h2 class="title is-3">Tools for evaluating ID-Matching performance of video captions</h2>
        <div class="content has-text-justified">
          <p>
            The three fundamental methods of LVLMs for annotating multiple frames, including ST, MTSC, and MTDC.

          </p>

          <img src="static\images\pic3.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">

          <p><br>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Enhancing ID-Matching in video captioning</h2>
        <div class="content has-text-justified">
          <p>
            Comparison of ST, MTSC, and MTDC across sequence similarity, precision, and recall. And results of the strength of SFS.
          </p>
        </div>


        <div class="columns is-multiline">
          <div class="column is-four-fifths">
            <img src="static\images\pic4.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">
          </div>
          <div class="column is-one-fifth">
            <img src="static\images\pic5.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">
          </div>
        </div>

        

        <div class="columns is-multiline">
          <div class="column is-half">
            <p>
               Illustration of GPT-4o’s success rate in identifying two people as the same based on descriptions with n features (“n tuple”), with base, contrast, and mixture modes. The success rate and robustness improve as n increases and descriptions become more similar.
            </p>
            <img src="static\images\pic6.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">
          </div>
          <div class="column is-half">
            
            <img src="static\images\pic7.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">
            <p>
              Overview of RICE, consisting of two techniques, MF and ETF.
            </p>
          </div>

        </div>

        <div class="content has-text-justified">
          <p>
            An example in which GPT-4o misidentifies individuals due to similar actions or similar environments. In contrast, identifying individuals based on features is more robust.
          </p>

          <img src="static\images\pic8.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">

        </div>

      </div>
    </div>
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static\images\pic9.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Pairwise comparisons in win rate on two datasets.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static\images\pic10.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Comparison of ID-Matching performance between ShareGPT4Video and RICE, along with ablation studies to evaluate the effectiveness of each component of RICE.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static\images\pic11.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Quantitative comparison between RICE implemented on Qwen-VL2.5 and Deepseekv3 and their baseline.
       </h2>
     </div>
     
  </div>
</div>
  </div>
  
</section>







<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-full">
        <h2 class="title is-3">Experiments</h2>
        <div class="content has-text-justified">


          <div class="columns is-multiline">
          <div class="column is-two-fifths">
            <img src="static\images\table1.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">
          </div>
          <div class="column is-three-fifth">
            <img src="static\images\table2.png" alt="Descriptive Image" style="max-width: 100%; height: auto;">
          </div>
          </div>



        </div>
      </div>
    </div>
  </div>
</section>

<!-- End image carousel -->




<!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
-->






<!-- Paper poster -->
<!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
-->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
